{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_propogation(parameters,cache,X,Y):\n",
    "    m=X.shape[1]\n",
    "    w1=parameters[\"w1\"]\n",
    "    w2=parameters[\"w2\"]\n",
    "    \n",
    "    A1=cache[\"A1\"]\n",
    "    A2=cache[\"A2\"]\n",
    "    \n",
    "    dZ2=A2-Y\n",
    "    dW2=dZ2.dot(A1.T)m\n",
    "    db2=np.sum(dZ2,axis=1,keepdims=True)/m\n",
    "    dZ1=W2.T.dot(dZ2)*(1-np.power(A1,2))\n",
    "    dW1=1/m * dZ1.dot(X,T)\n",
    "    db2=1/m * np.sum(dZ1,axis=1,keepdims=True)\n",
    "    \n",
    "    grads=(\"dW1\":dW1,\n",
    "           \"db1\":db1,\n",
    "           \"dW2\":dW2,\n",
    "           \"db2\":db2\n",
    "    )\n",
    "    \n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(parameters,grads,learning_rate=1.2):\n",
    "    W1=parameters[\"W1\"]\n",
    "    b1=parameters[\"b1\"]\n",
    "    W2=parameters[\"W2\"]\n",
    "    b2=parameters[\"b2\"]\n",
    "    \n",
    "    dw1=grads[\"dW1\"]\n",
    "    db1=grads[\"db1\"]\n",
    "    dw2=grads[\"dW2\"]\n",
    "    db2=grads[\"db2\"]\n",
    "    \n",
    "    W1=W1- learning_rate * dW1\n",
    "    b1=b1- learning_rate * db1\n",
    "    W2=W2- learning_rate * dW2\n",
    "    b2=b2- learning_rate * db2\n",
    "    \n",
    "    parameters={\"W1\":W1,\n",
    "                \"b1\":b1,\n",
    "                \"W2\":W2,\n",
    "                \"b2\":b2    \n",
    "    }\n",
    "    \n",
    "    return parameters\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hidden_layer_nn(X,Y,n_h,num_iterations=10000,print_cost=False):\n",
    "    np.random.seed(3)\n",
    "    (n_x,n_h,n_y)=network_structure(X,Y)\n",
    "    \n",
    "    parameters=parameters_init(n_x,n_h,n_y)\n",
    "    W1=parameters[\"W1\"]\n",
    "    b1=parameters[\"b1\"]\n",
    "    W2=parameters[\"W2\"]\n",
    "    b2=parameters[\"b2\"]\n",
    "    \n",
    "    for i in range(0,num_iterations):\n",
    "        A2,cache=forward_propogation(X,parameters)\n",
    "        cost=prediction_cost(A2,Y,parameters)\n",
    "        grads=backward_propogation(parameters,cache,X,Y)\n",
    "        parameters=update_parameters(parameters,grads)\n",
    "        if print_cost and 1% 100==0:\n",
    "            print ('cost after iteration %i: %f' %(i,cost))\n",
    "        \n",
    "    return parameters\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(parameters ,X):\n",
    "    A2,cache=forward_propogation(X,parameters)\n",
    "    predictions =(A2>0.5)\n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters =one_hidden_layer_nn(X,Y,n_h=4,num_iterations=10000,print_cost=True)\n",
    "\n",
    "plot_decision_boundary(lambda x:predict(parameters,x,T),X,Y)\n",
    "plt.title(\"desicion boundary for hidden layer size \"+str(4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
